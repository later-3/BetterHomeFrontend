#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Directus Work Order Batch Creation Script (V2 - cURL Edition)

This script reads a JSON definition file to batch-create work orders in Directus.
It uses `curl` for all network operations to ensure consistency with manual tests.

Features:
- Reads work order data from a flexible JSON structure.
- For each work order, uploads specified local files (images/videos) on the fly.
- Associates the newly uploaded files with the work order upon creation.
- Supports a --dry-run mode to test payloads without creating data.

Requires `curl` to be installed and available in the system's PATH.
"""

import argparse
import json
import os
import subprocess
from pathlib import Path
from typing import Optional

print("--- SCRIPT EXECUTION STARTED (cURL Edition) ---")

# --- Configuration ---
DIRECTUS_URL = os.getenv("DIRECTUS_URL", "http://localhost:8055")
TOKEN = os.getenv("DIRECTUS_TOKEN", "sfXUxkm3bEwOKO8fDKrZoClDQ4N08D0n")

# --- Constants ---
COMMUNITY_ID = "2a5c769e-9909-4331-99b3-983c8b1175c6"
DEFAULT_SUBMITTER_ID = os.getenv("SUBMITTER_ID", "1030a8c2-888e-4ff9-a9e8-d1b6a7c3d8ea")  # å¾è‹¥æ¥ 


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="é€šè¿‡ Directus API æ‰¹é‡åˆ›å»ºå·¥å• (V2 - cURL æŒ‰éœ€ä¸Šä¼ )ã€‚"
    )
    parser.add_argument("definition", help="æè¿°å·¥å•çš„ JSON æ–‡ä»¶çš„è·¯å¾„ã€‚ à¦¸à¦¨")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="æ‰“å°å°†è¦å‘é€çš„æ•°æ®ï¼Œä½†ä¸å®é™…åˆ›å»ºä»»ä½•å†…å®¹ã€‚"
    )
    return parser.parse_args()

def load_workorders_from_json(path: str) -> list:
    """ä» JSON æ–‡ä»¶åŠ è½½å·¥å•å®šä¹‰"""
    file_path = Path(path)
    if not file_path.exists():
        raise SystemExit(f"âŒ æ‰¾ä¸åˆ°å·¥å•å®šä¹‰æ–‡ä»¶: {path}")

    with file_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    candidates = data.get("workorders") if isinstance(data, dict) else data
    if not isinstance(candidates, list):
        raise SystemExit("âŒ JSON æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šåº”ä¸ºæ•°ç»„æˆ–åŒ…å« 'workorders' æ•°ç»„çš„å¯¹è±¡ã€‚ à¦¸à¦¨")
    return candidates

def fix_video_mime_type(file_id: str, file_path: Path) -> bool:
    """ä¿®å¤è§†é¢‘æ–‡ä»¶çš„ MIME ç±»å‹"""
    # æ£€æµ‹æ–‡ä»¶æ‰©å±•å
    ext = file_path.suffix.lower()
    mime_map = {
        '.mp4': 'video/mp4',
        '.mov': 'video/quicktime',
        '.avi': 'video/x-msvideo',
        '.mkv': 'video/x-matroska',
        '.webm': 'video/webm'
    }

    if ext not in mime_map:
        return True  # ä¸æ˜¯è§†é¢‘æ–‡ä»¶ï¼Œæ— éœ€ä¿®å¤

    correct_mime = mime_map[ext]
    print(f"       ğŸ”§ æ­£åœ¨ä¿®å¤è§†é¢‘ MIME ç±»å‹ä¸º: {correct_mime}")

    try:
        patch_data = json.dumps({"type": correct_mime})
        cmd = [
            "curl", "--noproxy", "*", "-s", "-X", "PATCH",
            "-H", f"Authorization: Bearer {TOKEN}",
            "-H", "Content-Type: application/json",
            "-d", patch_data,
            f"{DIRECTUS_URL}/files/{file_id}"
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=10)
        response_json = json.loads(result.stdout)

        if "errors" in response_json:
            print(f"       âš  MIME ç±»å‹ä¿®å¤å¤±è´¥: {response_json['errors'][0]['message']}")
            return False

        print(f"       âœ” MIME ç±»å‹å·²ä¿®å¤ä¸º: {correct_mime}")
        return True
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, json.JSONDecodeError) as e:
        print(f"       âš  MIME ç±»å‹ä¿®å¤å¤±è´¥: {e}")
        return False

def upload_file(local_path: str, dry_run: bool) -> Optional[str]:
    """ä½¿ç”¨ cURL ä¸Šä¼ å•ä¸ªæœ¬åœ°æ–‡ä»¶åˆ° Directus å¹¶è¿”å›å…¶ ID"""
    file_path = Path(local_path)
    if not file_path.exists():
        print(f"    âš  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¼ : {local_path}")
        return None

    if dry_run:
        print(f"    [dry-run] è®¡åˆ’ä¸Šä¼ æ–‡ä»¶: {local_path}")
        return f"dry-run-id-for-{file_path.name}"

    print(f"    â¬†ï¸ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶: {local_path}")
    try:
        cmd = [
            "curl", "--noproxy", "*", "-s", "-X", "POST",
            "-H", f"Authorization: Bearer {TOKEN}",
            "-F", f"file=@{local_path}",
            f"{DIRECTUS_URL}/files"
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        response_json = json.loads(result.stdout)

        if "errors" in response_json:
            print(f"       âœ– ä¸Šä¼ å¤±è´¥: {response_json['errors'][0]['message']}")
            return None

        file_id = response_json["data"]["id"]
        print(f"       âœ” ä¸Šä¼ æˆåŠŸ, æ–‡ä»¶ ID: {file_id}")

        # è‡ªåŠ¨ä¿®å¤è§†é¢‘æ–‡ä»¶çš„ MIME ç±»å‹
        fix_video_mime_type(file_id, file_path)

        return file_id
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError) as e:
        print(f"       âœ– ä¸Šä¼ å¤±è´¥ (cURL): {e}")
        if isinstance(e, subprocess.CalledProcessError):
            print(f"         - å“åº”: {e.stderr or e.stdout}")
    return None

def create_work_order(payload: dict, dry_run: bool):
    """ä½¿ç”¨ cURL åˆ›å»ºå•ä¸ªå·¥å•"""
    if dry_run:
        print("    [dry-run] å‡†å¤‡åˆ›å»ºå·¥å•ï¼Œæ•°æ®å¦‚ä¸‹:")
        print(json.dumps(payload, indent=2, ensure_ascii=False))
        return {"data": {"id": "dry-run-workorder-id"}}

    try:
        json_payload = json.dumps(payload)
        cmd = [
            "curl", "--noproxy", "*", "-s", "-X", "POST",
            "-H", f"Authorization: Bearer {TOKEN}",
            "-H", "Content-Type: application/json",
            "--data-binary", "@-",  # ä» stdin è¯»å–æ•°æ®
            f"{DIRECTUS_URL}/items/work_orders"
        ]
        result = subprocess.run(cmd, input=json_payload, capture_output=True, text=True, check=True, timeout=15)
        return json.loads(result.stdout)
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError) as e:
        print(f"       âœ– åˆ›å»ºå·¥å•å¤±è´¥ (cURL): {e}")
        if isinstance(e, subprocess.CalledProcessError):
            try:
                return json.loads(e.stdout or e.stderr)
            except json.JSONDecodeError:
                return {"errors": [{"message": e.stderr or e.stdout}]}
        return {"errors": [{"message": str(e)}]}

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("--- DEBUG: Entered main() function ---")
    args = parse_args()

    # --- Pre-flight Check ---
    print("--- é¢„æ£€: æ­£åœ¨æ£€æŸ¥æœåŠ¡å™¨è¿æ¥å’Œ Token... ---")
    try:
        cmd = ["curl", "--noproxy", "*", "-s", "-H", f"Authorization: Bearer {TOKEN}", f"{DIRECTUS_URL}/server/info"]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=10)
        response_json = json.loads(result.stdout)
        project_name = response_json.get("data", {}).get("project", {}).get("project_name", "Unknown Project")
        print(f"--- é¢„æ£€æˆåŠŸ: å·²è¿æ¥åˆ° Directus é¡¹ç›® \"{project_name}\" ---")
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError) as e:
        print(f"âŒ è‡´å‘½é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ° Directus æœåŠ¡å™¨æˆ– Token æ— æ•ˆã€‚ à¦¸à¦¨")
        print(f"   è¯·æ£€æŸ¥ DIRECTUS_URL (å½“å‰: {DIRECTUS_URL}) å’Œ DIRECTUS_TOKEN ç¯å¢ƒå˜é‡ï¼Œå¹¶ç¡®ä¿ 'curl' å·²å®‰è£…ã€‚ à¦¸à¦¨")
        if isinstance(e, subprocess.CalledProcessError):
            print(f"   é”™è¯¯è¯¦æƒ… (cURL): {e.stderr or e.stdout}")
        else:
            print(f"   é”™è¯¯è¯¦æƒ…: {e}")
        exit(1)
    # --- End Pre-flight Check ---

    workorders = load_workorders_from_json(args.definition)

    if not workorders:
        print("âš  JSON æ–‡ä»¶ä¸­æ²¡æœ‰ä»»ä½•å·¥å•æ¡ç›®")
        return

    print(f"\n======= å¼€å§‹æ‰¹é‡åˆ›å»ºå·¥å• (å…± {len(workorders)} æ¡) =======")

    for index, item in enumerate(workorders, start=1):
        print(f"\n--- ( {index}/{len(workorders)} ) æ­£åœ¨å¤„ç†å·¥å•: {item.get('title', 'æ— æ ‡é¢˜')} ---")

        try:
            uploaded_file_ids = []
            local_files = item.get("local_files", [])
            if isinstance(local_files, list) and local_files:
                print("  - å‘ç°éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶...")
                for file_path in local_files:
                    new_file_id = upload_file(file_path, args.dry_run)
                    if new_file_id:
                        uploaded_file_ids.append(new_file_id)
            
            payload = {
                "title": item["title"],
                "description": item["description"],
                "category": item["category"],
                "status": item.get("status", "submitted"),
                "priority": item.get("priority", "medium"),
                "community_id": COMMUNITY_ID,
                "submitter_id": item.get("submitter_id", DEFAULT_SUBMITTER_ID),
            }

            if uploaded_file_ids:
                payload["files"] = {"create": [{"directus_files_id": fid} for fid in uploaded_file_ids]}

            print("  - å‡†å¤‡åˆ›å»ºå·¥å•...")
            response = create_work_order(payload, args.dry_run)

            if response and response.get("data") and response.get("data").get("id"):
                workorder_id = response["data"]["id"]
                print(f"  âœ… å·¥å•åˆ›å»ºæˆåŠŸ! ID: {workorder_id}")
            else:
                error_msg = response.get("errors", "æœªçŸ¥é”™è¯¯")
                print(f"  âŒ å·¥å•åˆ›å»ºå¤±è´¥: {error_msg}")

        except KeyError as e:
            print(f"  âœ– æ•°æ®å‡†å¤‡å¤±è´¥: ç¼ºå°‘å¿…é¡»çš„å­—æ®µ {e}")
            print(f"    - å‡ºé”™çš„å·¥å•æ•°æ®: {item}")
            continue
        except Exception as e:
            print(f"  âœ– å¤„ç†å·¥å•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            continue

    print("\n======= æ‰¹é‡åˆ›å»ºå®Œæˆ =======")

# ç›´æ¥è°ƒç”¨ main å‡½æ•°
main()
